
import numpy as np

import theano
from theano import tensor as T
from sthor.operation import lcdnorm3
from sthor.util.pad import filter_pad2d

from bangmetric.correlation import  pearson
from bangmetric.precision_recall import average_precision
from skimage.util.shape import view_as_windows

from scipy.optimize import fmin_l_bfgs_b

DEFAULT_RF_SIZE = (21, 21)
DEFAULT_LNORM_SIZE = (11, 11)
DEFAULT_N_FILTERS = np.prod(DEFAULT_RF_SIZE)

DEFAULT_LBFGS_PARAMS = dict(
    iprint=1,
    factr=1e7,
    maxfun=1e4,
    )

#def zmun(X):
    #Xm = (X.T - X.mean(1).T).T
    #Xmn = (Xm.T / theano.tensor.sqrt((Xm ** 2.).sum(1)).T).T
    #return  Xmn

class RPLogReg1(object):

    def __init__(self,
                 rf_size=DEFAULT_RF_SIZE,
                 lnorm_size=DEFAULT_LNORM_SIZE,
                 n_filters=DEFAULT_N_FILTERS,
                 lbfgs_params=DEFAULT_LBFGS_PARAMS,
                ):

        self.rf_size = rf_size
        self.lnorm_size = lnorm_size
        self.n_filters = n_filters

        self.fb = None

        self.lbfgs_params = lbfgs_params

    def transform(self, X):

        rf_size = self.rf_size
        lnorm_size = self.lnorm_size
        l1_nfilters = self.n_filters
        X_shape = X.shape

        if lnorm_size is not None:
            X = filter_pad2d(np.atleast_3d(X), lnorm_size)
            X = lcdnorm3(X, lnorm_size)[..., 0]

        X = filter_pad2d(np.atleast_3d(X), rf_size)[..., 0]
        X = view_as_windows(X, rf_size)
        X = X.reshape(np.prod(X.shape[:2]), -1)

        print 'normalize...'
        X -= X.mean(0)
        X /= X.std(0)

        print 'dot...'
        if self.fb is None:
            fb = self.fb = np.random.randn(X.shape[1], l1_nfilters).astype('f')
        else:
            fb = self.fb
        X = np.dot(X, fb).clip(0, np.inf)

        print 'normalize...'
        X -= X.mean(0)
        X /= X.std(0)

        X = X.reshape(X_shape[:2] + (-1,))

        return X

    def fit(self, X, Y):

        X = self.transform(X)
        X = X.reshape(-1, X.shape[-1])

        Y = Y.reshape(Y.size, 1)
        #Y_true = Y.ravel()
        Y_true = Y.ravel().astype(long)

        # -- initial variables
        W = np.ones((X.shape[1], 2), dtype='float32')
        W_size = W.size
        W_shape = W.shape
        b = np.zeros((2), dtype='float32')

        # -- theano program
        _X = T.fmatrix()
        _b = T.fvector()
        _W = T.fmatrix()
        _Y_true = T.lvector()
        #_Y_true = T.fvector()

        _Y_pred = T.nnet.softmax(T.dot(_X, _W) + _b)
        #_loss = -T.mean(T.log(_Y_pred)[T.arange(_Y_true.shape[0]), _Y_true])
        #_Y_true_mn = zmun(_Y_true.astype('float64')).flatten()
        #_Y_pred_mn = zmun(_Y_pred).flatten()
        #_loss = -T.dot(_Y_true_mn, _Y_pred_mn)
        _loss = -T.mean(T.log(_Y_pred)[T.arange(_Y_true.shape[0]), _Y_true])
        #xx = _Y_true.flatten()
        #yy = _Y_pred[:, 1].flatten()
        #_loss = T.mean((xx - yy) ** 2.)

        _dloss_W = T.grad(_loss, _W)
        _dloss_b = T.grad(_loss, _b)

        _f = theano.function([_X, _W, _b],
                             [_Y_pred],
                             allow_input_downcast=True)

        _f_df = theano.function([_X, _Y_true, _W, _b],
                                [_Y_pred, _loss, _dloss_W, _dloss_b],
                                allow_input_downcast=True)

        def func(vars):
            # unpack W and b
            W = vars[:W_size].reshape(W_shape)
            b = vars[W_size:]
            Y_pred, loss, dloss_W, dloss_b = _f_df(X, Y_true, W, b)
            try:
                print 'ap', average_precision(Y_true.ravel(), Y_pred[:, 1].ravel())
                print 'pr', pearson(Y_true.ravel(), Y_pred[:, 1].ravel())
            except AssertionError:
                pass
            except ValueError:
                pass
            #print average_precision(a.ravel(), Y_pred.argmax(1).ravel())
            dloss = np.concatenate([dloss_W.ravel(), dloss_b.ravel()])
            return loss.astype('float64'), dloss.astype('float64')

        vars = np.concatenate([W.ravel(), b.ravel()])
        best, bestval, info = fmin_l_bfgs_b(func, vars, **self.lbfgs_params)

        self.W = best[:W_size].reshape(W_shape)
        self.b = best[W_size:]
        self._f = _f

        return self


    def predict(self, X):
        X_shape = X.shape

        X = self.transform(X)
        X = X.reshape(-1, X.shape[-1])

        Y_pred = self._f(X, self.W, self.b)[0][:, 1]
        Y_pred = Y_pred.reshape(X_shape[:2] + (-1,))

        return Y_pred
